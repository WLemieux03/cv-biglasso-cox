f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.001
xmax <- 100
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
y
range(y)
dx <- 0.1
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
y
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- (x + dx)/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
plot(y ~ x)
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
y
x[x == 9]
which(x == 9)
y[which(x == 9)]
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
y[which(x == 9)]
dx <- 0.001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.0001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.000001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.0001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
length(y)
dev.off()
x
dx <- 0.001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
length(y)
dx <- 0.001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.0001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.0001
xmax <- 10
x <- seq(-10, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.0001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) exp(-x)
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.0001
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 1/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 1/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
x
1/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 10*/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 10*x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 10/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 1/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
plot(y ~ x, lwd = 2)
plot(y ~ x, lwd = 2, type = 'l')
lines(1/x ~ x)
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 1/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, y)) #ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 10/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, y)) #ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 0.1/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, y)) #ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 0.01/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, y)) #ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 2, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(x) 0.01/x
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, y)) #ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 4, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(z) dx/z
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, y)) #ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 4, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
dx <- 0.01
xmax <- 10
x <- seq(0, xmax, by = dx)[-1]
y <- dx/x
f <- function(z) dx/z
plot(NA, xlab = "x", ylab = "y", log = 'x',
xlim = range(x), ylim = range(0, y)) #ylim = range(0, f(x)))
grid(); abline(h = 0, v = 0, lwd = 1.5, col = "gray75")
lines(f(x) ~ x, lwd = 8, col = rgb(0, 0, 0, 1))
lines(y ~ x, lwd = 2, col = "red")
cv.biglasso.cox <- function(x, y, lambda, nfolds, grouped = F, parallel = F, ...) {
# NOTE: The 'grouped' argument replicates the functionality of the 'grouped'
# argument in cv.glmnet for Cox models. Specifically, if grouped = F then it
# calculates the cross-validation error by the (weighted) mean of the test data
# partial-likelihoods using the coefficients from the training data. Meanwhile,
# if grouped = T then it calculates the error as the (weighted) mean of the
# difference between the full-data (train+test) and training data
# partial-likelihoods, both using the coefficients obtained from the training data.
# (I believe the ladder is the Verweij & Van Houwelingen method...
#  see https://arxiv.org/pdf/1905.10432.pdf for a comparison ["Basic" vs. "V&VH"])
n <- nrow(y)
# calculate the biglasso model over the sequence of (default) tuning parameters lambda
if (missing(lambda)) {
mod.init <- biglasso::biglasso(X = x, y = y, family = "cox", ...)
lambda.init <- mod.init$lambda
} else {
mod.init <- biglasso::biglasso(X = x, y = y, lambda = lambda, family = "cox", ...)
lambda.init <- lambda
}
# assign observations to cross-validation folds from 1, 2, ..., nfolds
folds <- sample(cut(1:n, breaks = nfolds, labels = F))
# list of integer vectors containing the row indices of x that will be use
# to fit the model (making use of the 'row.idx' argument in biglasso::biglasso())
train.row.idx <- lapply(1:nfolds, function(i) which(folds != i))
##### meat of the CV algorithm is here #####
train.fun <- function(trn.rows) {
tst.rows <- !((1:n) %in% trn.rows)
x.trn <- bigmemory::deepcopy(x = x, rows = trn.rows)
x.tst <- bigmemory::deepcopy(x = x, rows = tst.rows)
y.trn <- y[trn.rows,,drop=F]
y.tst <- y[tst.rows,,drop=F]
# compute training model and calculate training error
mod.trn <- biglasso::biglasso(X = x.trn, y = y.trn, lambda = lambda.init, family = "cox", ...)
### replicate Cox model cross-validation loss is computed in glmnet::glmnet()
# calculate the weight associated with the k-th CV fold (done in glmnet())
# NOTE: this could be lead to a division-by-zero if test set is too small (when all response
# observations are censored in the test set)
wt <- sum(y.tst[,"status"])
if (grouped) { # "V&VH cross-validation error"
plfull   <- glmnet::coxnet.deviance(x = x, y = y, beta = mod.trn$beta)
plminusk <- glmnet::coxnet.deviance(x = x.trn, y = y.trn, beta = mod.trn$beta)
loss.raw <- plfull - plminusk
} else { # "basic cross-validation error"
plk      <- glmnet::coxnet.deviance(x = x.tst, y = y.tst, beta = mod.trn$beta)
loss.raw <- plk
}
return (list("loss.tst"  = loss.raw/wt,
"weight"    = wt))
}
if (parallel) {
numCores <- detectCores()
cv.loss <- mclapply(train.row.idx, train.fun, mc.cores = numCores)
# these next two lines is a whole bunch of work just to replicate the format that
# I had from the non-parallel case. There is almost certainly a more efficient way
# of moving forwards
cv.loss <- unlist(cv.loss, recursive = F, use.names = F)
cv.loss <- array(cv.loss, dim = c(2, nfolds), dimnames = list(c("loss.tst", "weight"), NULL))
} else {
cv.loss <- sapply(train.row.idx, train.fun)
}
print(str(cv.loss))
# extract cross-validation loss values and organize into a set of matrices (nlambda x nfolds)
cv.loss.tst <- do.call("cbind", cv.loss["loss.tst",])
weights     <- unlist(cv.loss["weight",])
# average over all folds where each entry corresponds to a unique tuning value lambda
test.loss   <- apply(cv.loss.tst, 1, weighted.mean, w = weights)
# standard errors for test loss
test.loss.se <- sqrt(apply(scale(t(cv.loss.tst), test.loss, FALSE)^2, 2, weighted.mean,
w = weights)/(nfolds - 1))
test.loss.hi <- test.loss + test.loss.se
test.loss.lo <- test.loss - test.loss.se
best.lambdas <- getmin.lambda(mod.init$lambda, test.loss, test.loss.se)
out <- list()
out$model.fit    <- mod.init
out$test.loss    <- test.loss
out$test.loss.se <- test.loss.se
out$test.loss.hi <- test.loss.hi
out$test.loss.lo <- test.loss.lo
out$lambda       <- lambda.init
out$foldid       <- folds
out <- c(out, best.lambdas)
return (out)
}
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
library(biglasso)
library(glmnet)
library(data.table) # fread() so I can read fewer columns while testing, otherwise read.csv is fine
options(datatable.fread.datatable=FALSE) # format the data as a data.frame instead of a data.table
NCOLS <- 5000 # number of columns to load (fewer for quicker tests)
# load data
pt <- proc.time()
dat <- fread("./data/sample_SRTR_cleaned.csv", select = 1:NCOLS, # select columns (must contain columns 1-17)
na.strings = c("", "NA"), stringsAsFactors = T)
proc.time() - pt
# TEMPORARY: ignore NA/blank/missing cases
dat2 <- dat[complete.cases(dat),]
remove(dat) # remove the original data since it's quite large
# construct design matrix (excluding pID as this appears to be simply an identifier)
pt <- proc.time()
X1 <- model.matrix(~.-1, data = dat2[,1:14]) # confounders (note that we do not have an intercept column in a Cox model's design matirx)
X2 <- as.matrix(dat2[,18:ncol(dat2)] * 1.0)  # other variables/predictors
X <- cbind(X1, X2)
proc.time() - pt
# convert to big.matrix for biglasso
Xbig <- as.big.matrix(X)
# outcome variable & censor indicator (it may be a good idea to convert to a survival::is.Surv object)
y <- as.matrix(dat2[,c("surv", "fail_dc")])
colnames(y) <- c("time", "status")
#===========================================#
#================ RUN TESTS ================#
#===========================================#
# load custom R functions
lapply(list.files("./R/", full.names = T), source)
set.seed(124)
penalty  <- "enet"
alpha    <- 0.5
lambda   <- exp(seq(-1, -4, length.out = 100))
nfolds   <- 10
grouped  <- T
parallel <- F
pt <- proc.time()
cvout.bl <- cv.biglasso.cox(x        = Xbig,
y        = y,
penalty  = penalty,
alpha    = alpha,
lambda   = lambda,
nfolds   = nfolds,
grouped  = grouped,
parallel = parallel)
proc.time() - pt
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
#library(biglasso)
remove.packages('biglasso')
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
#library(biglasso)
remove.packages(biglasso)
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
#library(biglasso)
remove.packages("biglasso")
library(biglasso)
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
#remove.packages("biglasso")
devtools::install_github("dfleis/biglasso")
library(biglasso)
?biglasso
?cv.biglasso
?biglasso::cox.deviance()
?biglasso::cox.deviance
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
remove.packages("biglasso")
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
#remove.packages("biglasso")
devtools::install_github("dfleis/biglasso")
library(biglasso)
?cv.biglasso
?cv.biglasso
?biglasso
?biglasso
??biglasso
?glmnet
##
# Comparing glmnet & the (proposed) biglasso CV outputs
# for penalized Cox models
#
###
#=======================================#
#================ SETUP ================#
#=======================================#
#remove.packages("biglasso")
devtools::install_github("dfleis/biglasso")
library(biglasso)
?cv.biglasso
?biglasso::cv.biglasso
?biglasso::cox.deviance
?biglasso::biglasso
?biglasso::coef.cv.biglasso
?biglasso::setupX
